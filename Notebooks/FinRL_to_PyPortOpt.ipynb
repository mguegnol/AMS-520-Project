{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FinRL_to_PyPortOpt.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"IOXGMsMn04RC"}},{"cell_type":"code","source":["!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuXShHVyWvgM","executionInfo":{"status":"ok","timestamp":1639445700763,"user_tz":300,"elapsed":17862,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"outputId":"fb26652a-a7ac-45ce-8af4-c34d5cd16c58"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n","  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-aeh0z10f\n","  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-aeh0z10f\n","Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n","  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-318s1cz5/pyfolio_1bd09ae66aca42ad855c665a5a87c185\n","  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-318s1cz5/pyfolio_1bd09ae66aca42ad855c665a5a87c185\n","Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n","  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-318s1cz5/elegantrl_ec74dd853d9243a4a658389d419668f6\n","  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-318s1cz5/elegantrl_ec74dd853d9243a4a658389d419668f6\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.21.0)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.3.0)\n","Requirement already satisfied: stockstats in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.3.2)\n","Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.1.67)\n","Requirement already satisfied: elegantrl in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n","Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n","Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.3.0)\n","Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.9.0)\n","Requirement already satisfied: lz4 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.1.10)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (2.4.1)\n","Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.4.0)\n","Requirement already satisfied: exchange_calendars in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.5)\n","Requirement already satisfied: alpaca_trade_api in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.4.3)\n","Requirement already satisfied: ccxt in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.61.51)\n","Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.8.10)\n","Requirement already satisfied: wrds in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.1.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n","Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n","Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n","Requirement already satisfied: pre-commit in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (2.16.0)\n","Requirement already satisfied: pybullet in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (3.2.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (2.3.8)\n","Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.7.0)\n","Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n","Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.5.5)\n","Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.7.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n","Requirement already satisfied: aiohttp==3.7.4 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (3.7.4)\n","Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (1.2.3)\n","Requirement already satisfied: websockets<10,>=8.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (9.1)\n","Requirement already satisfied: msgpack==1.0.2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (1.0.2)\n","Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (5.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (5.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (1.6.3)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n","Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.3.3) (3.0.0)\n","Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.3.3) (36.0.0)\n","Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns>=1.1.1->ccxt->finrl==0.3.3) (4.1.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n","Requirement already satisfied: pyluach in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (1.3.0)\n","Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n","Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.0.2)\n","Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (0.4.14)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n","Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.7/dist-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.3) (3.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n","Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (3.3.1)\n","Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (1.6.0)\n","Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (20.10.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n","Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (2.4.0)\n","Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n","Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (0.3.4)\n","Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (1.1.1)\n","Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (2.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (4.0.2)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.3.11)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.0)\n","Requirement already satisfied: gpustat>=1.0.0b1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.0.0b1)\n","Requirement already satisfied: aioredis<2 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.3.1)\n","Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.2.0)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.2.0)\n","Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.5.4)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n","Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.7.0)\n","Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis<2->ray[default]->finrl==0.3.3) (2.0.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n","Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (1.19.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (1.2.13)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n","Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (0.1.2)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (21.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n","Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n","Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n","Requirement already satisfied: int-date>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from stockstats->finrl==0.3.3) (0.1.8)\n","Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.3) (2.9.2)\n","Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.3) (4.0.3)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n","\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# StockPortEnv - environment for RL algorithms\n","It defines action, states, rewards, environment."],"metadata":{"id":"LfhUNYWX1HOW"}},{"cell_type":"code","metadata":{"id":"CCMk_BDH5dRs","executionInfo":{"status":"ok","timestamp":1639445702125,"user_tz":300,"elapsed":1378,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"source":["import gym\n","from gym.utils import seeding\n","from gym import spaces\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","\n","\n","class StockPortfolioEnv(gym.Env):\n","    \"\"\"A single stock trading environment for OpenAI gym\n","\n","    Attributes\n","    ----------\n","        df: DataFrame\n","            input data\n","        stock_dim : int\n","            number of unique stocks\n","        hmax : int\n","            maximum number of shares to trade\n","        initial_amount : int\n","            start money\n","        transaction_cost_pct: float\n","            transaction cost percentage per trade\n","        reward_scaling: float\n","            scaling factor for reward, good for training\n","        state_space: int\n","            the dimension of input features\n","        action_space: int\n","            equals stock dimension\n","        tech_indicator_list: list\n","            a list of technical indicator names\n","        turbulence_threshold: int\n","            a threshold to control risk aversion\n","        day: int\n","            an increment number to control date\n","\n","    Methods\n","    -------\n","    _sell_stock()\n","        perform sell action based on the sign of the action\n","    _buy_stock()\n","        perform buy action based on the sign of the action\n","    step()\n","        at each step the agent will return actions, then \n","        we will calculate the reward, and return the next observation.\n","    reset()\n","        reset the environment\n","    render()\n","        use render to return other functions\n","    save_asset_memory()\n","        return account value at each time step\n","    save_action_memory()\n","        return actions/positions at each time step\n","        \n","\n","    \"\"\"\n","    metadata = {'render.modes': ['human']}\n","\n","    def __init__(self, \n","                df,\n","                stock_dim,\n","                hmax,\n","                initial_amount,\n","                transaction_cost_pct,\n","                reward_scaling,\n","                state_space,\n","                action_space,\n","                tech_indicator_list,\n","                turbulence_threshold=None,\n","                lookback=252,\n","                day = 0):\n","        #super(StockEnv, self).__init__()\n","        #money = 10 , scope = 1\n","        self.day = day\n","        self.lookback=lookback\n","        self.df = df\n","        self.stock_dim = stock_dim\n","        self.hmax = hmax\n","        self.initial_amount = initial_amount\n","        self.transaction_cost_pct =transaction_cost_pct\n","        self.reward_scaling = reward_scaling\n","        self.state_space = state_space\n","        self.action_space = action_space\n","        self.tech_indicator_list = tech_indicator_list\n","\n","        # action_space normalization and shape is self.stock_dim\n","        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n","        # Shape = (34, 30)\n","        # covariance matrix + technical indicators\n","        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n","\n","        # load data from a pandas dataframe\n","        self.data = self.df.loc[self.day,:]\n","        self.covs = self.data['cov_list'].values[0]\n","        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n","        self.terminal = False     \n","        self.turbulence_threshold = turbulence_threshold        \n","        # initalize state: inital portfolio return + individual stock return + individual weights\n","        self.portfolio_value = self.initial_amount\n","\n","        # memorize portfolio value each step\n","        self.asset_memory = [self.initial_amount]\n","        # memorize portfolio return each step\n","        self.portfolio_return_memory = [0]\n","        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n","        self.date_memory=[self.data.date.unique()[0]]\n","\n","        \n","    def step(self, actions):\n","        # print(self.day)\n","        self.terminal = self.day >= len(self.df.index.unique())-1\n","        # print(actions)\n","\n","        if self.terminal:\n","            df = pd.DataFrame(self.portfolio_return_memory)\n","            df.columns = ['daily_return']\n","            plt.plot(df.daily_return.cumsum(),'r')\n","            plt.savefig('results/cumulative_reward.png')\n","            plt.close()\n","            \n","            plt.plot(self.portfolio_return_memory,'r')\n","            plt.savefig('results/rewards.png')\n","            plt.close()\n","\n","            print(\"=================================\")\n","            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n","            print(\"end_total_asset:{}\".format(self.portfolio_value))\n","\n","            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n","            df_daily_return.columns = ['daily_return']\n","            if df_daily_return['daily_return'].std() !=0:\n","              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n","                       df_daily_return['daily_return'].std()\n","              print(\"Sharpe: \",sharpe)\n","            print(\"=================================\")\n","            \n","            return self.state, self.reward, self.terminal,{}\n","\n","        else:\n","            #print(\"Model actions: \",actions)\n","            # actions are the portfolio weight\n","            # normalize to sum of 1\n","            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n","            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n","            #else:\n","            #  norm_actions = actions\n","            weights = self.softmax_normalization(actions) \n","            #print(\"Normalized actions: \", weights)\n","            self.actions_memory.append(weights)\n","            last_day_memory = self.data\n","\n","            #load next state\n","            self.day += 1\n","            self.data = self.df.loc[self.day,:]\n","            self.covs = self.data['cov_list'].values[0]\n","            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n","            #print(self.state)\n","            # calcualte portfolio return\n","            # individual stocks' return * weight\n","            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n","            # update portfolio value\n","            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n","            self.portfolio_value = new_portfolio_value\n","\n","            # save into memory\n","            self.portfolio_return_memory.append(portfolio_return)\n","            self.date_memory.append(self.data.date.unique()[0])            \n","            self.asset_memory.append(new_portfolio_value)\n","\n","            # the reward is the new portfolio value or end portfolo value\n","            self.reward = new_portfolio_value \n","            #print(\"Step reward: \", self.reward)\n","            #self.reward = self.reward*self.reward_scaling\n","\n","        return self.state, self.reward, self.terminal, {}\n","\n","    def reset(self):\n","        self.asset_memory = [self.initial_amount]\n","        self.day = 0\n","        self.data = self.df.loc[self.day,:]\n","        # load states\n","        self.covs = self.data['cov_list'].values[0]\n","        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n","        self.portfolio_value = self.initial_amount\n","        #self.cost = 0\n","        #self.trades = 0\n","        self.terminal = False \n","        self.portfolio_return_memory = [0]\n","        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n","        self.date_memory=[self.data.date.unique()[0]] \n","        return self.state\n","    \n","    def render(self, mode='human'):\n","        return self.state\n","        \n","    def softmax_normalization(self, actions):\n","        numerator = np.exp(actions)\n","        denominator = np.sum(np.exp(actions))\n","        softmax_output = numerator/denominator\n","        return softmax_output\n","\n","    \n","    def save_asset_memory(self):\n","        date_list = self.date_memory\n","        portfolio_return = self.portfolio_return_memory\n","        #print(len(date_list))\n","        #print(len(asset_list))\n","        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n","        return df_account_value\n","\n","    def save_action_memory(self):\n","        # date and close price length must match actions length\n","        date_list = self.date_memory\n","        df_date = pd.DataFrame(date_list)\n","        df_date.columns = ['date']\n","        \n","        action_list = self.actions_memory\n","        df_actions = pd.DataFrame(action_list)\n","        df_actions.columns = self.data.tic.values\n","        df_actions.index = df_date.date\n","        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n","        return df_actions\n","\n","    def _seed(self, seed=None):\n","        self.np_random, seed = seeding.np_random(seed)\n","        return [seed]\n","\n","    def get_sb_env(self):\n","        e = DummyVecEnv([lambda: self])\n","        obs = e.reset()\n","        return e, obs"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# RL core function"],"metadata":{"id":"AelIjuT50-xj"}},{"cell_type":"code","source":["# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.use('Agg')\n","%matplotlib inline\n","import datetime\n","\n","# from StockPortfolioEnv import StockPortfolioEnv\n","\n","from finrl.apps import config\n","from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n","from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n","from finrl.finrl_meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n","from finrl.drl_agents.stablebaselines3.models import DRLAgent\n","from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n","\n","import os\n","if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n","    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n","if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n","    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n","if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n","    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n","if not os.path.exists(\"./\" + config.RESULTS_DIR):\n","    os.makedirs(\"./\" + config.RESULTS_DIR)"],"metadata":{"id":"-Vx3Yx4Fymvv","executionInfo":{"status":"ok","timestamp":1639445702719,"user_tz":300,"elapsed":605,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fa8329f-2733-4afc-9033-c4a1e0ebfcd8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n","  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"]}]},{"cell_type":"code","metadata":{"id":"gfamIc1W4yGN","executionInfo":{"status":"ok","timestamp":1639446838278,"user_tz":300,"elapsed":426,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"source":["def FinRL_PortfolioAllocation(\n","    start_date, end_date, train_end_date, ticker_list, lookback, model\n","):\n","    \"\"\"\n","    A Portfolio Allocation algorithm using different Reinforcement Learning \n","      models like A2C, PPO, DDPG, SAC, TD3.\n","\n","    Parameters\n","    ----------\n","    start_date : int\n","        Starting date of training set. \n","        Format: yyyy-mm-dd.\n","    end_date : str\n","        Ending date of training set; The day before starting date of trading set. \n","        Format: yyyy-mm-dd.\n","    train_end_date : str\n","        Ending date of training set.\n","        Format: yyyy-mm-dd.\n","    ticker_list : list\n","        Ticker list of stocks. \n","    lookback : int\n","        The lookback days (window range) of rolling windows of training. \n","        It must be greater than date difference of sta  \n","    model: str\n","        The string of model name. \n","        Available model: [\"A2C\",\"PPO\",\"DDPG\",\"SAC\",\"TD3\"]\n","        \n","    Returns\n","    -------\n","    df_daily_return : pd.DataFrame\n","        The daily returns during the trading period.\n","    df_actions : pd.DataFrame\n","        The portfolio allocation(weights) during the trading period.\n","    \"\"\"\n","    df = YahooDownloader(\n","        start_date=start_date, end_date=end_date, ticker_list=ticker_list\n","    ).fetch_data()\n","\n","    fe = FeatureEngineer(\n","        use_technical_indicator=True, use_turbulence=False, user_defined_feature=False\n","    )\n","\n","    df = fe.preprocess_data(df)\n","\n","    # add covariance matrix as states\n","    df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n","    df.index = df.date.factorize()[0]\n","\n","    cov_list = []\n","    return_list = []\n","\n","    lookback = lookback\n","    for i in range(lookback, len(df.index.unique())):\n","        data_lookback = df.loc[i - lookback : i, :]\n","        price_lookback = data_lookback.pivot_table(\n","            index=\"date\", columns=\"tic\", values=\"close\"\n","        )\n","        return_lookback = price_lookback.pct_change().dropna()\n","        return_list.append(return_lookback)\n","\n","        covs = return_lookback.cov().values\n","        cov_list.append(covs)\n","    df_cov = pd.DataFrame(\n","        {\n","            \"date\": df.date.unique()[lookback:],\n","            \"cov_list\": cov_list,\n","            \"return_list\": return_list,\n","        }\n","    )\n","    df = df.merge(df_cov, on=\"date\")\n","    df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n","\n","    train = data_split(df, start_date, train_end_date)\n","\n","    stock_dimension = len(train.tic.unique())\n","    state_space = stock_dimension\n","    # print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n","\n","    env_kwargs = {\n","        \"hmax\": 100,\n","        \"initial_amount\": 1000000,\n","        \"transaction_cost_pct\": 0.001,\n","        \"state_space\": state_space,\n","        \"stock_dim\": stock_dimension,\n","        \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST,\n","        \"action_space\": stock_dimension,\n","        \"reward_scaling\": 1e-4,\n","    }\n","\n","    e_train_gym = StockPortfolioEnv(df=train, **env_kwargs)\n","\n","    env_train, _ = e_train_gym.get_sb_env()\n","    # print(type(env_train))\n","\n","    # initialize\n","    agent = DRLAgent(env=env_train)\n","\n","    if model == \"A2C\":\n","        A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n","        model_a2c = agent.get_model(model_name=\"a2c\", model_kwargs=A2C_PARAMS)\n","\n","        trained_model = agent.train_model(\n","            model=model_a2c, tb_log_name=\"a2c\", total_timesteps=100000\n","        )\n","    elif model == \"PPO\":\n","        PPO_PARAMS = {\n","            \"n_steps\": 2048,\n","            \"ent_coef\": 0.005,\n","            \"learning_rate\": 0.0001,\n","            \"batch_size\": 128,\n","        }\n","        model_ppo = agent.get_model(\"ppo\", model_kwargs=PPO_PARAMS)\n","\n","        trained_model = agent.train_model(\n","            model=model_ppo, tb_log_name=\"ppo\", total_timesteps=80\n","        )\n","    elif model == \"DDPG\":\n","        DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n","        model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS)\n","\n","        trained_model = agent.train_model(\n","            model=model_ddpg, tb_log_name=\"ddpg\", total_timesteps=2000\n","        )\n","    elif model == \"SAC\":\n","        SAC_PARAMS = {\n","            \"batch_size\": 128,\n","            \"buffer_size\": 100000,\n","            \"learning_rate\": 0.0003,\n","            \"learning_starts\": 100,\n","            \"ent_coef\": \"auto_0.1\",\n","        }\n","        model_sac = agent.get_model(\"sac\", model_kwargs=SAC_PARAMS)\n","\n","        trained_model = agent.train_model(\n","            model=model_sac, tb_log_name=\"sac\", total_timesteps=5000\n","        )\n","    elif model == \"TD3\":\n","        TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n","        model_td3 = agent.get_model(\"td3\", model_kwargs=TD3_PARAMS)\n","\n","        trained_model = agent.train_model(\n","            model=model_td3, tb_log_name=\"td3\", total_timesteps=300\n","        )\n","\n","    # The day before starting date of trading set \n","    #   is the starting day of trading.\n","    trade = data_split(df, train_end_date, end_date)\n","    e_trade_gym = StockPortfolioEnv(df=trade, **env_kwargs)\n","\n","    # DRLAgent.save(model+'.zip')\n","\n","    df_daily_return, df_actions = DRLAgent.DRL_prediction(\n","        model=trained_model, environment=e_trade_gym\n","    )\n","\n","    return df_daily_return, df_actions"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"wWocb30H1zBe"}},{"cell_type":"code","source":["# start_date,\n","# end_date,\n","# train_end_date,\n","# ticker_list,\n","# lookback,\n","# model\n","test_return, test_action = FinRL_PortfolioAllocation('2017-01-01', '2021-11-03', '2021-01-01', config.DOW_30_TICKER, 60, 'A2C')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RV6wVUfYHrF","executionInfo":{"status":"ok","timestamp":1639447466812,"user_tz":300,"elapsed":625797,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"outputId":"10917eb7-d4bd-4214-fd36-fa1644f0f0e9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (35982, 8)\n","Successfully added technical indicators\n","{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n","Using cuda device\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 189       |\n","|    iterations         | 100       |\n","|    time_elapsed       | 2         |\n","|    total_timesteps    | 500       |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 99        |\n","|    policy_loss        | 1.66e+08  |\n","|    reward             | 1358483.8 |\n","|    std                | 0.998     |\n","|    value_loss         | 2e+13     |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1744163.0928624575\n","Sharpe:  0.7898964885748819\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 174       |\n","|    iterations         | 200       |\n","|    time_elapsed       | 5         |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 199       |\n","|    policy_loss        | 1.24e+08  |\n","|    reward             | 1031010.2 |\n","|    std                | 0.998     |\n","|    value_loss         | 1.13e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 300       |\n","|    time_elapsed       | 8         |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 299       |\n","|    policy_loss        | 1.61e+08  |\n","|    reward             | 1408373.4 |\n","|    std                | 0.998     |\n","|    value_loss         | 1.97e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1817067.0666617346\n","Sharpe:  0.8493221389042765\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 175       |\n","|    iterations         | 400       |\n","|    time_elapsed       | 11        |\n","|    total_timesteps    | 2000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 399       |\n","|    policy_loss        | 1.31e+08  |\n","|    reward             | 1089885.1 |\n","|    std                | 0.998     |\n","|    value_loss         | 1.25e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 500       |\n","|    time_elapsed       | 14        |\n","|    total_timesteps    | 2500      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 499       |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1408079.2 |\n","|    std                | 0.998     |\n","|    value_loss         | 2.13e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1808345.2572044865\n","Sharpe:  0.8358354352191313\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 600       |\n","|    time_elapsed       | 16        |\n","|    total_timesteps    | 3000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 599       |\n","|    policy_loss        | 1.42e+08  |\n","|    reward             | 1142487.4 |\n","|    std                | 0.997     |\n","|    value_loss         | 1.39e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 700       |\n","|    time_elapsed       | 19        |\n","|    total_timesteps    | 3500      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 699       |\n","|    policy_loss        | 1.81e+08  |\n","|    reward             | 1505454.5 |\n","|    std                | 0.997     |\n","|    value_loss         | 2.36e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1844346.7746576045\n","Sharpe:  0.864626714534575\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 800       |\n","|    time_elapsed       | 22        |\n","|    total_timesteps    | 4000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 799       |\n","|    policy_loss        | 1.54e+08  |\n","|    reward             | 1289785.5 |\n","|    std                | 0.997     |\n","|    value_loss         | 1.79e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 900       |\n","|    time_elapsed       | 25        |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 899       |\n","|    policy_loss        | 1.98e+08  |\n","|    reward             | 1631852.6 |\n","|    std                | 0.996     |\n","|    value_loss         | 2.93e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1847800.6764751035\n","Sharpe:  0.8719556168966855\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 1000      |\n","|    time_elapsed       | 28        |\n","|    total_timesteps    | 5000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 999       |\n","|    policy_loss        | 1.51e+08  |\n","|    reward             | 1207714.5 |\n","|    std                | 0.996     |\n","|    value_loss         | 1.5e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 30        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | 1.57e+08  |\n","|    reward             | 1358532.5 |\n","|    std                | 0.995     |\n","|    value_loss         | 1.75e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1748975.073529027\n","Sharpe:  0.7941037731923164\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 1200      |\n","|    time_elapsed       | 33        |\n","|    total_timesteps    | 6000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1199      |\n","|    policy_loss        | 1.59e+08  |\n","|    reward             | 1243360.1 |\n","|    std                | 0.996     |\n","|    value_loss         | 1.61e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1300      |\n","|    time_elapsed       | 36        |\n","|    total_timesteps    | 6500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1299      |\n","|    policy_loss        | 1.81e+08  |\n","|    reward             | 1477700.5 |\n","|    std                | 0.996     |\n","|    value_loss         | 2.35e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1806833.0547767826\n","Sharpe:  0.8309315552378289\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 1400      |\n","|    time_elapsed       | 39        |\n","|    total_timesteps    | 7000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1399      |\n","|    policy_loss        | 1.45e+08  |\n","|    reward             | 1324961.9 |\n","|    std                | 0.995     |\n","|    value_loss         | 1.82e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 41        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | 1.95e+08  |\n","|    reward             | 1595853.5 |\n","|    std                | 0.994     |\n","|    value_loss         | 2.77e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1813393.0711393587\n","Sharpe:  0.8432476835877722\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 44        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | 1.59e+08  |\n","|    reward             | 1305174.9 |\n","|    std                | 0.994     |\n","|    value_loss         | 1.75e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1700      |\n","|    time_elapsed       | 47        |\n","|    total_timesteps    | 8500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1699      |\n","|    policy_loss        | 2.04e+08  |\n","|    reward             | 1747828.9 |\n","|    std                | 0.994     |\n","|    value_loss         | 3.17e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1820699.2691485677\n","Sharpe:  0.8448412331854457\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 50        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1401622.5 |\n","|    std                | 0.994     |\n","|    value_loss         | 2e+13     |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1974604.5851083864\n","Sharpe:  0.9407131922031898\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 1900      |\n","|    time_elapsed       | 53        |\n","|    total_timesteps    | 9500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1899      |\n","|    policy_loss        | 1.29e+08  |\n","|    reward             | 1013827.3 |\n","|    std                | 0.994     |\n","|    value_loss         | 1.11e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 2000      |\n","|    time_elapsed       | 56        |\n","|    total_timesteps    | 10000     |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 1999      |\n","|    policy_loss        | 1.81e+08  |\n","|    reward             | 1413585.1 |\n","|    std                | 0.994     |\n","|    value_loss         | 2.23e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1858635.3670332164\n","Sharpe:  0.8657963870881825\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2100      |\n","|    time_elapsed       | 59        |\n","|    total_timesteps    | 10500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2099      |\n","|    policy_loss        | 1.3e+08   |\n","|    reward             | 1066503.6 |\n","|    std                | 0.993     |\n","|    value_loss         | 1.18e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 178       |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 61        |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1495083.9 |\n","|    std                | 0.993     |\n","|    value_loss         | 2.38e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1878048.8213371867\n","Sharpe:  0.88620666041912\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 64        |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | 1.37e+08  |\n","|    reward             | 1099999.2 |\n","|    std                | 0.993     |\n","|    value_loss         | 1.28e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2400      |\n","|    time_elapsed       | 67        |\n","|    total_timesteps    | 12000     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2399      |\n","|    policy_loss        | 1.74e+08  |\n","|    reward             | 1458102.4 |\n","|    std                | 0.992     |\n","|    value_loss         | 2.31e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1865778.8707006378\n","Sharpe:  0.8727118519958522\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2500      |\n","|    time_elapsed       | 70        |\n","|    total_timesteps    | 12500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2499      |\n","|    policy_loss        | 1.57e+08  |\n","|    reward             | 1224112.0 |\n","|    std                | 0.993     |\n","|    value_loss         | 1.59e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 73        |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | 1.9e+08   |\n","|    reward             | 1568995.1 |\n","|    std                | 0.992     |\n","|    value_loss         | 2.56e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1811428.6781268166\n","Sharpe:  0.8361896066306155\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2700      |\n","|    time_elapsed       | 76        |\n","|    total_timesteps    | 13500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2699      |\n","|    policy_loss        | 1.52e+08  |\n","|    reward             | 1234609.0 |\n","|    std                | 0.991     |\n","|    value_loss         | 1.62e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2800      |\n","|    time_elapsed       | 78        |\n","|    total_timesteps    | 14000     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2799      |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1175951.5 |\n","|    std                | 0.991     |\n","|    value_loss         | 2.2e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1777262.624561125\n","Sharpe:  0.8142343942579654\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 2900      |\n","|    time_elapsed       | 81        |\n","|    total_timesteps    | 14500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2899      |\n","|    policy_loss        | 1.42e+08  |\n","|    reward             | 1255753.2 |\n","|    std                | 0.992     |\n","|    value_loss         | 1.7e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 84        |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | 1.67e+08  |\n","|    reward             | 1392073.8 |\n","|    std                | 0.991     |\n","|    value_loss         | 1.88e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1691359.0854868426\n","Sharpe:  0.7523916326159076\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3100      |\n","|    time_elapsed       | 87        |\n","|    total_timesteps    | 15500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3099      |\n","|    policy_loss        | 1.71e+08  |\n","|    reward             | 1308509.6 |\n","|    std                | 0.991     |\n","|    value_loss         | 1.82e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3200      |\n","|    time_elapsed       | 90        |\n","|    total_timesteps    | 16000     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3199      |\n","|    policy_loss        | 1.71e+08  |\n","|    reward             | 1532945.1 |\n","|    std                | 0.99      |\n","|    value_loss         | 2.31e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1729071.8169142124\n","Sharpe:  0.7774631465097044\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 93        |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1300844.1 |\n","|    std                | 0.99      |\n","|    value_loss         | 1.79e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 95        |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | 1.92e+08  |\n","|    reward             | 1550236.0 |\n","|    std                | 0.99      |\n","|    value_loss         | 2.75e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1798074.3600877516\n","Sharpe:  0.8275920425657088\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3500      |\n","|    time_elapsed       | 98        |\n","|    total_timesteps    | 17500     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3499      |\n","|    policy_loss        | 1.44e+08  |\n","|    reward             | 1304461.6 |\n","|    std                | 0.989     |\n","|    value_loss         | 1.72e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1836207.4416481568\n","Sharpe:  0.8525299293964285\n","=================================\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 176      |\n","|    iterations         | 3600     |\n","|    time_elapsed       | 101      |\n","|    total_timesteps    | 18000    |\n","| train/                |          |\n","|    entropy_loss       | -40.8    |\n","|    explained_variance | 1.19e-07 |\n","|    learning_rate      | 0.0002   |\n","|    n_updates          | 3599     |\n","|    policy_loss        | 1.16e+08 |\n","|    reward             | 998761.1 |\n","|    std                | 0.988    |\n","|    value_loss         | 1.03e+13 |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 104       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | 1.69e+08  |\n","|    reward             | 1440118.6 |\n","|    std                | 0.988     |\n","|    value_loss         | 2.12e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1739108.1873754826\n","Sharpe:  0.7848517860004873\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 3800      |\n","|    time_elapsed       | 107       |\n","|    total_timesteps    | 19000     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3799      |\n","|    policy_loss        | 1.25e+08  |\n","|    reward             | 1033832.7 |\n","|    std                | 0.988     |\n","|    value_loss         | 1.14e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 110       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | 1.84e+08  |\n","|    reward             | 1461829.2 |\n","|    std                | 0.987     |\n","|    value_loss         | 2.17e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1795213.0795037586\n","Sharpe:  0.822272239227699\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 4000      |\n","|    time_elapsed       | 113       |\n","|    total_timesteps    | 20000     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 3999      |\n","|    policy_loss        | 1.32e+08  |\n","|    reward             | 1078723.2 |\n","|    std                | 0.987     |\n","|    value_loss         | 1.22e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4100      |\n","|    time_elapsed       | 115       |\n","|    total_timesteps    | 20500     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4099      |\n","|    policy_loss        | 1.73e+08  |\n","|    reward             | 1455532.9 |\n","|    std                | 0.987     |\n","|    value_loss         | 2.12e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1797565.6364724285\n","Sharpe:  0.8223623753456999\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 4200      |\n","|    time_elapsed       | 118       |\n","|    total_timesteps    | 21000     |\n","| train/                |           |\n","|    entropy_loss       | -40.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4199      |\n","|    policy_loss        | 1.33e+08  |\n","|    reward             | 1127048.0 |\n","|    std                | 0.987     |\n","|    value_loss         | 1.33e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4300      |\n","|    time_elapsed       | 121       |\n","|    total_timesteps    | 21500     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4299      |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1446907.9 |\n","|    std                | 0.986     |\n","|    value_loss         | 2.21e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1760271.0747169615\n","Sharpe:  0.7970250740997893\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 4400      |\n","|    time_elapsed       | 124       |\n","|    total_timesteps    | 22000     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4399      |\n","|    policy_loss        | 1.51e+08  |\n","|    reward             | 1201100.1 |\n","|    std                | 0.986     |\n","|    value_loss         | 1.64e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4500      |\n","|    time_elapsed       | 126       |\n","|    total_timesteps    | 22500     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4499      |\n","|    policy_loss        | 1.98e+08  |\n","|    reward             | 1605039.2 |\n","|    std                | 0.986     |\n","|    value_loss         | 2.67e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1810312.0301519465\n","Sharpe:  0.8360360469272583\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4600      |\n","|    time_elapsed       | 129       |\n","|    total_timesteps    | 23000     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4599      |\n","|    policy_loss        | 1.61e+08  |\n","|    reward             | 1203649.0 |\n","|    std                | 0.985     |\n","|    value_loss         | 1.6e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4700      |\n","|    time_elapsed       | 132       |\n","|    total_timesteps    | 23500     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4699      |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1400724.9 |\n","|    std                | 0.985     |\n","|    value_loss         | 2.1e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1827095.346852662\n","Sharpe:  0.839866994291412\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4800      |\n","|    time_elapsed       | 135       |\n","|    total_timesteps    | 24000     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4799      |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1273692.1 |\n","|    std                | 0.984     |\n","|    value_loss         | 1.65e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 4900      |\n","|    time_elapsed       | 138       |\n","|    total_timesteps    | 24500     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4899      |\n","|    policy_loss        | 1.63e+08  |\n","|    reward             | 1443733.0 |\n","|    std                | 0.983     |\n","|    value_loss         | 2.17e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1726736.1792900797\n","Sharpe:  0.7680907887365727\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5000      |\n","|    time_elapsed       | 141       |\n","|    total_timesteps    | 25000     |\n","| train/                |           |\n","|    entropy_loss       | -40.7     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 4999      |\n","|    policy_loss        | 1.73e+08  |\n","|    reward             | 1352298.0 |\n","|    std                | 0.983     |\n","|    value_loss         | 1.95e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5100      |\n","|    time_elapsed       | 143       |\n","|    total_timesteps    | 25500     |\n","| train/                |           |\n","|    entropy_loss       | -40.6     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5099      |\n","|    policy_loss        | 1.87e+08  |\n","|    reward             | 1518292.6 |\n","|    std                | 0.983     |\n","|    value_loss         | 2.67e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1750923.0055673392\n","Sharpe:  0.7847794513660564\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5200      |\n","|    time_elapsed       | 146       |\n","|    total_timesteps    | 26000     |\n","| train/                |           |\n","|    entropy_loss       | -40.6     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5199      |\n","|    policy_loss        | 1.67e+08  |\n","|    reward             | 1254666.2 |\n","|    std                | 0.982     |\n","|    value_loss         | 1.81e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5300      |\n","|    time_elapsed       | 149       |\n","|    total_timesteps    | 26500     |\n","| train/                |           |\n","|    entropy_loss       | -40.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5299      |\n","|    policy_loss        | 1.98e+08  |\n","|    reward             | 1685320.6 |\n","|    std                | 0.981     |\n","|    value_loss         | 2.93e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1714014.1279580828\n","Sharpe:  0.7692251691327734\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5400      |\n","|    time_elapsed       | 152       |\n","|    total_timesteps    | 27000     |\n","| train/                |           |\n","|    entropy_loss       | -40.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5399      |\n","|    policy_loss        | 1.66e+08  |\n","|    reward             | 1402916.8 |\n","|    std                | 0.981     |\n","|    value_loss         | 2.12e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1845512.9943791053\n","Sharpe:  0.8547181317313577\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5500      |\n","|    time_elapsed       | 155       |\n","|    total_timesteps    | 27500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5499      |\n","|    policy_loss        | 1.17e+08  |\n","|    reward             | 1007736.7 |\n","|    std                | 0.98      |\n","|    value_loss         | 1.1e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5600      |\n","|    time_elapsed       | 157       |\n","|    total_timesteps    | 28000     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5599      |\n","|    policy_loss        | 1.54e+08  |\n","|    reward             | 1363828.0 |\n","|    std                | 0.979     |\n","|    value_loss         | 1.98e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1787293.7673402806\n","Sharpe:  0.8095100647053224\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5700      |\n","|    time_elapsed       | 160       |\n","|    total_timesteps    | 28500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5699      |\n","|    policy_loss        | 1.28e+08  |\n","|    reward             | 1069794.4 |\n","|    std                | 0.979     |\n","|    value_loss         | 1.2e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5800      |\n","|    time_elapsed       | 163       |\n","|    total_timesteps    | 29000     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5799      |\n","|    policy_loss        | 1.88e+08  |\n","|    reward             | 1418937.6 |\n","|    std                | 0.979     |\n","|    value_loss         | 2.39e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1856567.5255358615\n","Sharpe:  0.8676593115562518\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 5900      |\n","|    time_elapsed       | 166       |\n","|    total_timesteps    | 29500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5899      |\n","|    policy_loss        | 1.34e+08  |\n","|    reward             | 1141691.6 |\n","|    std                | 0.979     |\n","|    value_loss         | 1.35e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6000      |\n","|    time_elapsed       | 169       |\n","|    total_timesteps    | 30000     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 5999      |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1482161.0 |\n","|    std                | 0.979     |\n","|    value_loss         | 2.28e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1834266.9756492036\n","Sharpe:  0.8463922849166627\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6100      |\n","|    time_elapsed       | 172       |\n","|    total_timesteps    | 30500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6099      |\n","|    policy_loss        | 1.44e+08  |\n","|    reward             | 1237095.6 |\n","|    std                | 0.978     |\n","|    value_loss         | 1.56e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6200      |\n","|    time_elapsed       | 174       |\n","|    total_timesteps    | 31000     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6199      |\n","|    policy_loss        | 1.99e+08  |\n","|    reward             | 1614436.0 |\n","|    std                | 0.978     |\n","|    value_loss         | 2.77e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1819525.6355626478\n","Sharpe:  0.8406539065459708\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6300      |\n","|    time_elapsed       | 177       |\n","|    total_timesteps    | 31500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6299      |\n","|    policy_loss        | 1.57e+08  |\n","|    reward             | 1207959.8 |\n","|    std                | 0.977     |\n","|    value_loss         | 1.68e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6400      |\n","|    time_elapsed       | 180       |\n","|    total_timesteps    | 32000     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6399      |\n","|    policy_loss        | 1.43e+08  |\n","|    reward             | 1106839.5 |\n","|    std                | 0.977     |\n","|    value_loss         | 1.73e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1855739.2430689654\n","Sharpe:  0.8651195145195009\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6500      |\n","|    time_elapsed       | 183       |\n","|    total_timesteps    | 32500     |\n","| train/                |           |\n","|    entropy_loss       | -40.5     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6499      |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1266408.6 |\n","|    std                | 0.977     |\n","|    value_loss         | 1.64e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6600      |\n","|    time_elapsed       | 185       |\n","|    total_timesteps    | 33000     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6599      |\n","|    policy_loss        | 1.86e+08  |\n","|    reward             | 1636601.9 |\n","|    std                | 0.976     |\n","|    value_loss         | 2.45e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1824601.4322925443\n","Sharpe:  0.849779959355432\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6700      |\n","|    time_elapsed       | 188       |\n","|    total_timesteps    | 33500     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6699      |\n","|    policy_loss        | 1.56e+08  |\n","|    reward             | 1313720.4 |\n","|    std                | 0.976     |\n","|    value_loss         | 1.78e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6800      |\n","|    time_elapsed       | 191       |\n","|    total_timesteps    | 34000     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6799      |\n","|    policy_loss        | 1.79e+08  |\n","|    reward             | 1547489.6 |\n","|    std                | 0.976     |\n","|    value_loss         | 2.58e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1799281.6090180252\n","Sharpe:  0.8287019226503993\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 6900      |\n","|    time_elapsed       | 194       |\n","|    total_timesteps    | 34500     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6899      |\n","|    policy_loss        | 1.46e+08  |\n","|    reward             | 1327651.6 |\n","|    std                | 0.976     |\n","|    value_loss         | 1.77e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7000      |\n","|    time_elapsed       | 197       |\n","|    total_timesteps    | 35000     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 6999      |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1519754.9 |\n","|    std                | 0.975     |\n","|    value_loss         | 2.29e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1693935.0892759638\n","Sharpe:  0.7514989614322565\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7100      |\n","|    time_elapsed       | 200       |\n","|    total_timesteps    | 35500     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7099      |\n","|    policy_loss        | 1.66e+08  |\n","|    reward             | 1332995.0 |\n","|    std                | 0.975     |\n","|    value_loss         | 1.87e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1847625.7596356007\n","Sharpe:  0.861010841002606\n","=================================\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 177      |\n","|    iterations         | 7200     |\n","|    time_elapsed       | 203      |\n","|    total_timesteps    | 36000    |\n","| train/                |          |\n","|    entropy_loss       | -40.4    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0002   |\n","|    n_updates          | 7199     |\n","|    policy_loss        | 1.22e+08 |\n","|    reward             | 998210.4 |\n","|    std                | 0.974    |\n","|    value_loss         | 1.06e+13 |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7300      |\n","|    time_elapsed       | 205       |\n","|    total_timesteps    | 36500     |\n","| train/                |           |\n","|    entropy_loss       | -40.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7299      |\n","|    policy_loss        | 1.72e+08  |\n","|    reward             | 1398874.9 |\n","|    std                | 0.973     |\n","|    value_loss         | 2.05e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1747798.9265548934\n","Sharpe:  0.7914908755979457\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7400      |\n","|    time_elapsed       | 208       |\n","|    total_timesteps    | 37000     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7399      |\n","|    policy_loss        | 1.2e+08   |\n","|    reward             | 1026481.8 |\n","|    std                | 0.973     |\n","|    value_loss         | 1.13e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7500      |\n","|    time_elapsed       | 211       |\n","|    total_timesteps    | 37500     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7499      |\n","|    policy_loss        | 1.72e+08  |\n","|    reward             | 1437573.8 |\n","|    std                | 0.972     |\n","|    value_loss         | 2.17e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1774782.0332352358\n","Sharpe:  0.8088974806882766\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7600      |\n","|    time_elapsed       | 214       |\n","|    total_timesteps    | 38000     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7599      |\n","|    policy_loss        | 1.31e+08  |\n","|    reward             | 1105160.5 |\n","|    std                | 0.971     |\n","|    value_loss         | 1.26e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7700      |\n","|    time_elapsed       | 216       |\n","|    total_timesteps    | 38500     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7699      |\n","|    policy_loss        | 1.79e+08  |\n","|    reward             | 1485134.2 |\n","|    std                | 0.971     |\n","|    value_loss         | 2.34e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1810544.3019202515\n","Sharpe:  0.8349647890576409\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7800      |\n","|    time_elapsed       | 220       |\n","|    total_timesteps    | 39000     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7799      |\n","|    policy_loss        | 1.35e+08  |\n","|    reward             | 1179389.6 |\n","|    std                | 0.971     |\n","|    value_loss         | 1.43e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 7900      |\n","|    time_elapsed       | 222       |\n","|    total_timesteps    | 39500     |\n","| train/                |           |\n","|    entropy_loss       | -40.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7899      |\n","|    policy_loss        | 1.62e+08  |\n","|    reward             | 1535906.5 |\n","|    std                | 0.971     |\n","|    value_loss         | 2.51e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1797938.9413703096\n","Sharpe:  0.8260322477129638\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8000      |\n","|    time_elapsed       | 225       |\n","|    total_timesteps    | 40000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 7999      |\n","|    policy_loss        | 1.34e+08  |\n","|    reward             | 1221507.6 |\n","|    std                | 0.97      |\n","|    value_loss         | 1.54e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8100      |\n","|    time_elapsed       | 228       |\n","|    total_timesteps    | 40500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8099      |\n","|    policy_loss        | 1.95e+08  |\n","|    reward             | 1659376.8 |\n","|    std                | 0.968     |\n","|    value_loss         | 2.95e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1884232.307919361\n","Sharpe:  0.8830712450150255\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8200      |\n","|    time_elapsed       | 231       |\n","|    total_timesteps    | 41000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8199      |\n","|    policy_loss        | 1.47e+08  |\n","|    reward             | 1243038.4 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.6e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8300      |\n","|    time_elapsed       | 234       |\n","|    total_timesteps    | 41500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8299      |\n","|    policy_loss        | 1.76e+08  |\n","|    reward             | 1355151.8 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.99e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1757938.9738132241\n","Sharpe:  0.8042272024125269\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8400      |\n","|    time_elapsed       | 237       |\n","|    total_timesteps    | 42000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8399      |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1264315.6 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.65e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 8500      |\n","|    time_elapsed       | 239       |\n","|    total_timesteps    | 42500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8499      |\n","|    policy_loss        | 1.58e+08  |\n","|    reward             | 1472808.2 |\n","|    std                | 0.968     |\n","|    value_loss         | 2.2e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1686612.5136445228\n","Sharpe:  0.7506971846880278\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 8600      |\n","|    time_elapsed       | 243       |\n","|    total_timesteps    | 43000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8599      |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1358949.6 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.99e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 8700      |\n","|    time_elapsed       | 245       |\n","|    total_timesteps    | 43500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8699      |\n","|    policy_loss        | 2.03e+08  |\n","|    reward             | 1613051.4 |\n","|    std                | 0.969     |\n","|    value_loss         | 2.6e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1808280.2355432052\n","Sharpe:  0.8326867689693195\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 8800      |\n","|    time_elapsed       | 248       |\n","|    total_timesteps    | 44000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8799      |\n","|    policy_loss        | 1.49e+08  |\n","|    reward             | 1232218.2 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.78e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 8900      |\n","|    time_elapsed       | 251       |\n","|    total_timesteps    | 44500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8899      |\n","|    policy_loss        | 2.22e+08  |\n","|    reward             | 1843071.1 |\n","|    std                | 0.968     |\n","|    value_loss         | 3.61e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1869530.8271210638\n","Sharpe:  0.8788831611642544\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9000      |\n","|    time_elapsed       | 254       |\n","|    total_timesteps    | 45000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 8999      |\n","|    policy_loss        | 1.64e+08  |\n","|    reward             | 1351955.0 |\n","|    std                | 0.967     |\n","|    value_loss         | 1.9e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1770745.7827028339\n","Sharpe:  0.8076831135880544\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9100      |\n","|    time_elapsed       | 257       |\n","|    total_timesteps    | 45500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9099      |\n","|    policy_loss        | 1.28e+08  |\n","|    reward             | 1030249.3 |\n","|    std                | 0.968     |\n","|    value_loss         | 1.09e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9200      |\n","|    time_elapsed       | 260       |\n","|    total_timesteps    | 46000     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9199      |\n","|    policy_loss        | 1.69e+08  |\n","|    reward             | 1376280.0 |\n","|    std                | 0.967     |\n","|    value_loss         | 2.11e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1865540.493979164\n","Sharpe:  0.8650311423057596\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9300      |\n","|    time_elapsed       | 263       |\n","|    total_timesteps    | 46500     |\n","| train/                |           |\n","|    entropy_loss       | -40.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9299      |\n","|    policy_loss        | 1.28e+08  |\n","|    reward             | 1052844.9 |\n","|    std                | 0.966     |\n","|    value_loss         | 1.2e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9400      |\n","|    time_elapsed       | 265       |\n","|    total_timesteps    | 47000     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9399      |\n","|    policy_loss        | 1.62e+08  |\n","|    reward             | 1395789.4 |\n","|    std                | 0.966     |\n","|    value_loss         | 2.14e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1818696.8930405644\n","Sharpe:  0.8401172846678628\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9500      |\n","|    time_elapsed       | 268       |\n","|    total_timesteps    | 47500     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9499      |\n","|    policy_loss        | 1.36e+08  |\n","|    reward             | 1134117.0 |\n","|    std                | 0.966     |\n","|    value_loss         | 1.36e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9600      |\n","|    time_elapsed       | 271       |\n","|    total_timesteps    | 48000     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9599      |\n","|    policy_loss        | 1.83e+08  |\n","|    reward             | 1490270.4 |\n","|    std                | 0.966     |\n","|    value_loss         | 2.31e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1846654.6970224972\n","Sharpe:  0.8552857491939001\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9700      |\n","|    time_elapsed       | 274       |\n","|    total_timesteps    | 48500     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9699      |\n","|    policy_loss        | 1.52e+08  |\n","|    reward             | 1244996.6 |\n","|    std                | 0.966     |\n","|    value_loss         | 1.57e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9800      |\n","|    time_elapsed       | 277       |\n","|    total_timesteps    | 49000     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9799      |\n","|    policy_loss        | 2e+08     |\n","|    reward             | 1567911.5 |\n","|    std                | 0.965     |\n","|    value_loss         | 2.55e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1764897.0338691906\n","Sharpe:  0.799688160962994\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 9900      |\n","|    time_elapsed       | 280       |\n","|    total_timesteps    | 49500     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9899      |\n","|    policy_loss        | 1.52e+08  |\n","|    reward             | 1203495.4 |\n","|    std                | 0.965     |\n","|    value_loss         | 1.55e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10000     |\n","|    time_elapsed       | 282       |\n","|    total_timesteps    | 50000     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 9999      |\n","|    policy_loss        | 1.45e+08  |\n","|    reward             | 1239254.2 |\n","|    std                | 0.964     |\n","|    value_loss         | 1.53e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1865884.7353680425\n","Sharpe:  0.8665486224893317\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10100     |\n","|    time_elapsed       | 285       |\n","|    total_timesteps    | 50500     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10099     |\n","|    policy_loss        | 1.41e+08  |\n","|    reward             | 1220791.9 |\n","|    std                | 0.964     |\n","|    value_loss         | 1.67e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10200     |\n","|    time_elapsed       | 288       |\n","|    total_timesteps    | 51000     |\n","| train/                |           |\n","|    entropy_loss       | -40.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10199     |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1551956.9 |\n","|    std                | 0.963     |\n","|    value_loss         | 2.79e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1858369.4415394126\n","Sharpe:  0.8632033502085402\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10300     |\n","|    time_elapsed       | 291       |\n","|    total_timesteps    | 51500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10299     |\n","|    policy_loss        | 1.61e+08  |\n","|    reward             | 1326310.4 |\n","|    std                | 0.963     |\n","|    value_loss         | 1.88e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10400     |\n","|    time_elapsed       | 293       |\n","|    total_timesteps    | 52000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10399     |\n","|    policy_loss        | 1.7e+08   |\n","|    reward             | 1603351.6 |\n","|    std                | 0.962     |\n","|    value_loss         | 2.58e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1787496.7519024187\n","Sharpe:  0.8132563782720479\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10500     |\n","|    time_elapsed       | 296       |\n","|    total_timesteps    | 52500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10499     |\n","|    policy_loss        | 1.42e+08  |\n","|    reward             | 1262713.5 |\n","|    std                | 0.963     |\n","|    value_loss         | 1.83e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10600     |\n","|    time_elapsed       | 299       |\n","|    total_timesteps    | 53000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10599     |\n","|    policy_loss        | 1.72e+08  |\n","|    reward             | 1678418.4 |\n","|    std                | 0.962     |\n","|    value_loss         | 2.61e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1729818.0339529843\n","Sharpe:  0.7727974079259292\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10700     |\n","|    time_elapsed       | 302       |\n","|    total_timesteps    | 53500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10699     |\n","|    policy_loss        | 1.5e+08   |\n","|    reward             | 1335912.8 |\n","|    std                | 0.961     |\n","|    value_loss         | 1.87e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1830610.51774137\n","Sharpe:  0.8426445530486676\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10800     |\n","|    time_elapsed       | 305       |\n","|    total_timesteps    | 54000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10799     |\n","|    policy_loss        | 1.14e+08  |\n","|    reward             | 1011169.7 |\n","|    std                | 0.961     |\n","|    value_loss         | 1.06e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 10900     |\n","|    time_elapsed       | 308       |\n","|    total_timesteps    | 54500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10899     |\n","|    policy_loss        | 1.82e+08  |\n","|    reward             | 1447244.6 |\n","|    std                | 0.961     |\n","|    value_loss         | 2.21e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1792229.8118705868\n","Sharpe:  0.8187167875081539\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11000     |\n","|    time_elapsed       | 310       |\n","|    total_timesteps    | 55000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 10999     |\n","|    policy_loss        | 1.26e+08  |\n","|    reward             | 1050278.2 |\n","|    std                | 0.961     |\n","|    value_loss         | 1.15e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11100     |\n","|    time_elapsed       | 313       |\n","|    total_timesteps    | 55500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11099     |\n","|    policy_loss        | 1.68e+08  |\n","|    reward             | 1454475.2 |\n","|    std                | 0.961     |\n","|    value_loss         | 2.19e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1761101.9856458185\n","Sharpe:  0.7988650195875899\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11200     |\n","|    time_elapsed       | 316       |\n","|    total_timesteps    | 56000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11199     |\n","|    policy_loss        | 1.36e+08  |\n","|    reward             | 1105310.0 |\n","|    std                | 0.96      |\n","|    value_loss         | 1.3e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 11300     |\n","|    time_elapsed       | 319       |\n","|    total_timesteps    | 56500     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11299     |\n","|    policy_loss        | 1.77e+08  |\n","|    reward             | 1479366.2 |\n","|    std                | 0.96      |\n","|    value_loss         | 2.37e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1857792.0821199412\n","Sharpe:  0.8568264174524585\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11400     |\n","|    time_elapsed       | 322       |\n","|    total_timesteps    | 57000     |\n","| train/                |           |\n","|    entropy_loss       | -40       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11399     |\n","|    policy_loss        | 1.47e+08  |\n","|    reward             | 1207579.2 |\n","|    std                | 0.96      |\n","|    value_loss         | 1.52e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11500     |\n","|    time_elapsed       | 324       |\n","|    total_timesteps    | 57500     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | 2.38e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11499     |\n","|    policy_loss        | 1.73e+08  |\n","|    reward             | 1518467.0 |\n","|    std                | 0.96      |\n","|    value_loss         | 2.43e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1760243.9327781224\n","Sharpe:  0.7963208931868662\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11600     |\n","|    time_elapsed       | 327       |\n","|    total_timesteps    | 58000     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11599     |\n","|    policy_loss        | 1.45e+08  |\n","|    reward             | 1248978.9 |\n","|    std                | 0.959     |\n","|    value_loss         | 1.69e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 11700     |\n","|    time_elapsed       | 330       |\n","|    total_timesteps    | 58500     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11699     |\n","|    policy_loss        | 1.93e+08  |\n","|    reward             | 1461782.1 |\n","|    std                | 0.958     |\n","|    value_loss         | 2.95e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1863514.2496416678\n","Sharpe:  0.8618980723970274\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 11800     |\n","|    time_elapsed       | 333       |\n","|    total_timesteps    | 59000     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11799     |\n","|    policy_loss        | 1.48e+08  |\n","|    reward             | 1222012.6 |\n","|    std                | 0.957     |\n","|    value_loss         | 1.58e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 11900     |\n","|    time_elapsed       | 336       |\n","|    total_timesteps    | 59500     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11899     |\n","|    policy_loss        | 1.49e+08  |\n","|    reward             | 1349800.9 |\n","|    std                | 0.957     |\n","|    value_loss         | 1.97e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1828594.6088160248\n","Sharpe:  0.8431718731005196\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 12000     |\n","|    time_elapsed       | 339       |\n","|    total_timesteps    | 60000     |\n","| train/                |           |\n","|    entropy_loss       | -39.9     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 11999     |\n","|    policy_loss        | 1.46e+08  |\n","|    reward             | 1302872.0 |\n","|    std                | 0.957     |\n","|    value_loss         | 1.79e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12100     |\n","|    time_elapsed       | 341       |\n","|    total_timesteps    | 60500     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12099     |\n","|    policy_loss        | 1.87e+08  |\n","|    reward             | 1503249.2 |\n","|    std                | 0.956     |\n","|    value_loss         | 2.53e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1801225.6431784446\n","Sharpe:  0.8229158021755488\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 12200     |\n","|    time_elapsed       | 344       |\n","|    total_timesteps    | 61000     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12199     |\n","|    policy_loss        | 1.44e+08  |\n","|    reward             | 1301560.9 |\n","|    std                | 0.955     |\n","|    value_loss         | 1.85e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12300     |\n","|    time_elapsed       | 347       |\n","|    total_timesteps    | 61500     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12299     |\n","|    policy_loss        | 1.76e+08  |\n","|    reward             | 1554154.9 |\n","|    std                | 0.955     |\n","|    value_loss         | 2.48e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1708777.0439502653\n","Sharpe:  0.7629908871229344\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12400     |\n","|    time_elapsed       | 350       |\n","|    total_timesteps    | 62000     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12399     |\n","|    policy_loss        | 1.48e+08  |\n","|    reward             | 1263950.2 |\n","|    std                | 0.955     |\n","|    value_loss         | 1.58e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12500     |\n","|    time_elapsed       | 352       |\n","|    total_timesteps    | 62500     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12499     |\n","|    policy_loss        | 2.1e+08   |\n","|    reward             | 1781495.5 |\n","|    std                | 0.954     |\n","|    value_loss         | 3.33e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1793821.2427842892\n","Sharpe:  0.8265490680025819\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12600     |\n","|    time_elapsed       | 355       |\n","|    total_timesteps    | 63000     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12599     |\n","|    policy_loss        | 1.63e+08  |\n","|    reward             | 1358120.4 |\n","|    std                | 0.954     |\n","|    value_loss         | 2.01e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1800112.7283751715\n","Sharpe:  0.8213316499588568\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 12700     |\n","|    time_elapsed       | 358       |\n","|    total_timesteps    | 63500     |\n","| train/                |           |\n","|    entropy_loss       | -39.8     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12699     |\n","|    policy_loss        | 1.14e+08  |\n","|    reward             | 1031895.2 |\n","|    std                | 0.953     |\n","|    value_loss         | 1.12e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 12800     |\n","|    time_elapsed       | 361       |\n","|    total_timesteps    | 64000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12799     |\n","|    policy_loss        | 1.48e+08  |\n","|    reward             | 1372012.9 |\n","|    std                | 0.953     |\n","|    value_loss         | 1.84e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1797623.293261176\n","Sharpe:  0.8195716319664037\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 12900     |\n","|    time_elapsed       | 364       |\n","|    total_timesteps    | 64500     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12899     |\n","|    policy_loss        | 1.35e+08  |\n","|    reward             | 1071931.4 |\n","|    std                | 0.953     |\n","|    value_loss         | 1.22e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 13000     |\n","|    time_elapsed       | 367       |\n","|    total_timesteps    | 65000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 12999     |\n","|    policy_loss        | 1.52e+08  |\n","|    reward             | 1409869.9 |\n","|    std                | 0.952     |\n","|    value_loss         | 2.16e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1759440.9677674929\n","Sharpe:  0.7963050107389466\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13100     |\n","|    time_elapsed       | 370       |\n","|    total_timesteps    | 65500     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13099     |\n","|    policy_loss        | 1.42e+08  |\n","|    reward             | 1147122.0 |\n","|    std                | 0.952     |\n","|    value_loss         | 1.4e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 13200     |\n","|    time_elapsed       | 372       |\n","|    total_timesteps    | 66000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13199     |\n","|    policy_loss        | 1.79e+08  |\n","|    reward             | 1484071.2 |\n","|    std                | 0.951     |\n","|    value_loss         | 2.24e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1707701.580891367\n","Sharpe:  0.756175128350915\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13300     |\n","|    time_elapsed       | 375       |\n","|    total_timesteps    | 66500     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13299     |\n","|    policy_loss        | 1.51e+08  |\n","|    reward             | 1268928.9 |\n","|    std                | 0.951     |\n","|    value_loss         | 1.7e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 177       |\n","|    iterations         | 13400     |\n","|    time_elapsed       | 378       |\n","|    total_timesteps    | 67000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13399     |\n","|    policy_loss        | 1.79e+08  |\n","|    reward             | 1529334.0 |\n","|    std                | 0.951     |\n","|    value_loss         | 2.58e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1704034.9813301994\n","Sharpe:  0.7555801299194944\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13500     |\n","|    time_elapsed       | 381       |\n","|    total_timesteps    | 67500     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13499     |\n","|    policy_loss        | 1.5e+08   |\n","|    reward             | 1260564.1 |\n","|    std                | 0.951     |\n","|    value_loss         | 1.6e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13600     |\n","|    time_elapsed       | 384       |\n","|    total_timesteps    | 68000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13599     |\n","|    policy_loss        | 1.57e+08  |\n","|    reward             | 1415865.8 |\n","|    std                | 0.951     |\n","|    value_loss         | 1.79e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1881125.94556629\n","Sharpe:  0.8729334755359888\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13700     |\n","|    time_elapsed       | 387       |\n","|    total_timesteps    | 68500     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13699     |\n","|    policy_loss        | 1.45e+08  |\n","|    reward             | 1227203.1 |\n","|    std                | 0.951     |\n","|    value_loss         | 1.63e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13800     |\n","|    time_elapsed       | 389       |\n","|    total_timesteps    | 69000     |\n","| train/                |           |\n","|    entropy_loss       | -39.7     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13799     |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1446466.6 |\n","|    std                | 0.95      |\n","|    value_loss         | 2.45e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1810105.422816103\n","Sharpe:  0.8287101787782084\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 13900     |\n","|    time_elapsed       | 392       |\n","|    total_timesteps    | 69500     |\n","| train/                |           |\n","|    entropy_loss       | -39.6     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13899     |\n","|    policy_loss        | 1.55e+08  |\n","|    reward             | 1354350.8 |\n","|    std                | 0.95      |\n","|    value_loss         | 1.93e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14000     |\n","|    time_elapsed       | 395       |\n","|    total_timesteps    | 70000     |\n","| train/                |           |\n","|    entropy_loss       | -39.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 13999     |\n","|    policy_loss        | 1.96e+08  |\n","|    reward             | 1569794.5 |\n","|    std                | 0.949     |\n","|    value_loss         | 2.76e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1794952.1488805646\n","Sharpe:  0.8157471026201703\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14100     |\n","|    time_elapsed       | 398       |\n","|    total_timesteps    | 70500     |\n","| train/                |           |\n","|    entropy_loss       | -39.6     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14099     |\n","|    policy_loss        | 1.53e+08  |\n","|    reward             | 1353227.6 |\n","|    std                | 0.948     |\n","|    value_loss         | 1.8e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14200     |\n","|    time_elapsed       | 401       |\n","|    total_timesteps    | 71000     |\n","| train/                |           |\n","|    entropy_loss       | -39.6     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14199     |\n","|    policy_loss        | 2.02e+08  |\n","|    reward             | 1749889.9 |\n","|    std                | 0.948     |\n","|    value_loss         | 3.15e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1812579.8771917736\n","Sharpe:  0.832213870561585\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14300     |\n","|    time_elapsed       | 404       |\n","|    total_timesteps    | 71500     |\n","| train/                |           |\n","|    entropy_loss       | -39.6     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14299     |\n","|    policy_loss        | 1.56e+08  |\n","|    reward             | 1378078.8 |\n","|    std                | 0.947     |\n","|    value_loss         | 1.93e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1824741.3112143073\n","Sharpe:  0.8450927854386211\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14400     |\n","|    time_elapsed       | 407       |\n","|    total_timesteps    | 72000     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14399     |\n","|    policy_loss        | 1.21e+08  |\n","|    reward             | 1013911.4 |\n","|    std                | 0.947     |\n","|    value_loss         | 1.1e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14500     |\n","|    time_elapsed       | 410       |\n","|    total_timesteps    | 72500     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14499     |\n","|    policy_loss        | 1.61e+08  |\n","|    reward             | 1390134.9 |\n","|    std                | 0.946     |\n","|    value_loss         | 2.15e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1762852.9622422704\n","Sharpe:  0.7977722314580468\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14600     |\n","|    time_elapsed       | 413       |\n","|    total_timesteps    | 73000     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14599     |\n","|    policy_loss        | 1.21e+08  |\n","|    reward             | 1068862.4 |\n","|    std                | 0.946     |\n","|    value_loss         | 1.19e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14700     |\n","|    time_elapsed       | 415       |\n","|    total_timesteps    | 73500     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14699     |\n","|    policy_loss        | 1.69e+08  |\n","|    reward             | 1449649.8 |\n","|    std                | 0.946     |\n","|    value_loss         | 2.23e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1759174.0638791032\n","Sharpe:  0.7975465786908448\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14800     |\n","|    time_elapsed       | 418       |\n","|    total_timesteps    | 74000     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14799     |\n","|    policy_loss        | 1.3e+08   |\n","|    reward             | 1124675.1 |\n","|    std                | 0.945     |\n","|    value_loss         | 1.32e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 14900     |\n","|    time_elapsed       | 421       |\n","|    total_timesteps    | 74500     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14899     |\n","|    policy_loss        | 1.85e+08  |\n","|    reward             | 1476190.2 |\n","|    std                | 0.945     |\n","|    value_loss         | 2.4e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1923002.4423450849\n","Sharpe:  0.9022419272407348\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15000     |\n","|    time_elapsed       | 424       |\n","|    total_timesteps    | 75000     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 14999     |\n","|    policy_loss        | 1.4e+08   |\n","|    reward             | 1202941.6 |\n","|    std                | 0.944     |\n","|    value_loss         | 1.53e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15100     |\n","|    time_elapsed       | 427       |\n","|    total_timesteps    | 75500     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15099     |\n","|    policy_loss        | 1.9e+08   |\n","|    reward             | 1529878.6 |\n","|    std                | 0.944     |\n","|    value_loss         | 2.4e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1795163.2278490071\n","Sharpe:  0.818562465757087\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15200     |\n","|    time_elapsed       | 430       |\n","|    total_timesteps    | 76000     |\n","| train/                |           |\n","|    entropy_loss       | -39.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15199     |\n","|    policy_loss        | 1.43e+08  |\n","|    reward             | 1230442.4 |\n","|    std                | 0.944     |\n","|    value_loss         | 1.6e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15300     |\n","|    time_elapsed       | 432       |\n","|    total_timesteps    | 76500     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15299     |\n","|    policy_loss        | 1.7e+08   |\n","|    reward             | 1384940.1 |\n","|    std                | 0.943     |\n","|    value_loss         | 2.21e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1772282.0984527753\n","Sharpe:  0.8014813622756458\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15400     |\n","|    time_elapsed       | 435       |\n","|    total_timesteps    | 77000     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15399     |\n","|    policy_loss        | 1.38e+08  |\n","|    reward             | 1238020.9 |\n","|    std                | 0.943     |\n","|    value_loss         | 1.64e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15500     |\n","|    time_elapsed       | 438       |\n","|    total_timesteps    | 77500     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15499     |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1443643.5 |\n","|    std                | 0.943     |\n","|    value_loss         | 2e+13     |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1835337.8744140049\n","Sharpe:  0.8449999150703407\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15600     |\n","|    time_elapsed       | 441       |\n","|    total_timesteps    | 78000     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15599     |\n","|    policy_loss        | 1.47e+08  |\n","|    reward             | 1278711.0 |\n","|    std                | 0.942     |\n","|    value_loss         | 1.76e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15700     |\n","|    time_elapsed       | 444       |\n","|    total_timesteps    | 78500     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15699     |\n","|    policy_loss        | 1.81e+08  |\n","|    reward             | 1606108.5 |\n","|    std                | 0.941     |\n","|    value_loss         | 2.54e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1850734.8967842085\n","Sharpe:  0.8548839084334573\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15800     |\n","|    time_elapsed       | 447       |\n","|    total_timesteps    | 79000     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15799     |\n","|    policy_loss        | 1.58e+08  |\n","|    reward             | 1249635.6 |\n","|    std                | 0.941     |\n","|    value_loss         | 1.81e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 15900     |\n","|    time_elapsed       | 450       |\n","|    total_timesteps    | 79500     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15899     |\n","|    policy_loss        | 2.03e+08  |\n","|    reward             | 1627613.2 |\n","|    std                | 0.942     |\n","|    value_loss         | 2.89e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1802433.5771433548\n","Sharpe:  0.821198711412125\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16000     |\n","|    time_elapsed       | 453       |\n","|    total_timesteps    | 80000     |\n","| train/                |           |\n","|    entropy_loss       | -39.4     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 15999     |\n","|    policy_loss        | 1.42e+08  |\n","|    reward             | 1277746.6 |\n","|    std                | 0.941     |\n","|    value_loss         | 1.68e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1777975.7306844208\n","Sharpe:  0.8086251342166706\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16100     |\n","|    time_elapsed       | 456       |\n","|    total_timesteps    | 80500     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16099     |\n","|    policy_loss        | 2.15e+08  |\n","|    reward             | 997921.8  |\n","|    std                | 0.94      |\n","|    value_loss         | 3.34e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16200     |\n","|    time_elapsed       | 458       |\n","|    total_timesteps    | 81000     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16199     |\n","|    policy_loss        | 1.53e+08  |\n","|    reward             | 1387825.5 |\n","|    std                | 0.94      |\n","|    value_loss         | 1.97e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1816912.1001319885\n","Sharpe:  0.8359987689532068\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16300     |\n","|    time_elapsed       | 461       |\n","|    total_timesteps    | 81500     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16299     |\n","|    policy_loss        | 1.1e+08   |\n","|    reward             | 1037925.5 |\n","|    std                | 0.94      |\n","|    value_loss         | 1.14e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16400     |\n","|    time_elapsed       | 464       |\n","|    total_timesteps    | 82000     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16399     |\n","|    policy_loss        | 1.81e+08  |\n","|    reward             | 1426342.6 |\n","|    std                | 0.94      |\n","|    value_loss         | 2.09e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1798543.9502424113\n","Sharpe:  0.8253268043801741\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16500     |\n","|    time_elapsed       | 467       |\n","|    total_timesteps    | 82500     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16499     |\n","|    policy_loss        | 1.14e+08  |\n","|    reward             | 1069179.9 |\n","|    std                | 0.94      |\n","|    value_loss         | 1.21e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16600     |\n","|    time_elapsed       | 470       |\n","|    total_timesteps    | 83000     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16599     |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1491369.0 |\n","|    std                | 0.939     |\n","|    value_loss         | 2.27e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1850411.1472365346\n","Sharpe:  0.8572056080288782\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16700     |\n","|    time_elapsed       | 473       |\n","|    total_timesteps    | 83500     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16699     |\n","|    policy_loss        | 1.25e+08  |\n","|    reward             | 1150105.5 |\n","|    std                | 0.938     |\n","|    value_loss         | 1.38e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16800     |\n","|    time_elapsed       | 476       |\n","|    total_timesteps    | 84000     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16799     |\n","|    policy_loss        | 1.77e+08  |\n","|    reward             | 1537726.4 |\n","|    std                | 0.938     |\n","|    value_loss         | 2.48e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1876692.157402671\n","Sharpe:  0.8729320923164363\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 16900     |\n","|    time_elapsed       | 479       |\n","|    total_timesteps    | 84500     |\n","| train/                |           |\n","|    entropy_loss       | -39.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16899     |\n","|    policy_loss        | 1.55e+08  |\n","|    reward             | 1160407.1 |\n","|    std                | 0.937     |\n","|    value_loss         | 1.74e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17000     |\n","|    time_elapsed       | 481       |\n","|    total_timesteps    | 85000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 16999     |\n","|    policy_loss        | 1.88e+08  |\n","|    reward             | 1652966.8 |\n","|    std                | 0.937     |\n","|    value_loss         | 2.81e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1810182.6230834678\n","Sharpe:  0.8327191953400361\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17100     |\n","|    time_elapsed       | 485       |\n","|    total_timesteps    | 85500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17099     |\n","|    policy_loss        | 1.49e+08  |\n","|    reward             | 1222895.5 |\n","|    std                | 0.936     |\n","|    value_loss         | 1.64e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17200     |\n","|    time_elapsed       | 487       |\n","|    total_timesteps    | 86000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17199     |\n","|    policy_loss        | 1.72e+08  |\n","|    reward             | 1366656.2 |\n","|    std                | 0.937     |\n","|    value_loss         | 2.05e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1884067.5176379688\n","Sharpe:  0.8767768147439662\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17300     |\n","|    time_elapsed       | 490       |\n","|    total_timesteps    | 86500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17299     |\n","|    policy_loss        | 1.43e+08  |\n","|    reward             | 1262327.9 |\n","|    std                | 0.937     |\n","|    value_loss         | 1.59e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17400     |\n","|    time_elapsed       | 493       |\n","|    total_timesteps    | 87000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17399     |\n","|    policy_loss        | 1.67e+08  |\n","|    reward             | 1477622.5 |\n","|    std                | 0.937     |\n","|    value_loss         | 2.23e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1764294.7843913424\n","Sharpe:  0.8020455178253558\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17500     |\n","|    time_elapsed       | 496       |\n","|    total_timesteps    | 87500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17499     |\n","|    policy_loss        | 1.58e+08  |\n","|    reward             | 1344363.2 |\n","|    std                | 0.936     |\n","|    value_loss         | 1.89e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17600     |\n","|    time_elapsed       | 499       |\n","|    total_timesteps    | 88000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17599     |\n","|    policy_loss        | 1.76e+08  |\n","|    reward             | 1521654.4 |\n","|    std                | 0.936     |\n","|    value_loss         | 2.57e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1772469.8906269544\n","Sharpe:  0.8034005279563599\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17700     |\n","|    time_elapsed       | 502       |\n","|    total_timesteps    | 88500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17699     |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1306684.8 |\n","|    std                | 0.935     |\n","|    value_loss         | 1.94e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17800     |\n","|    time_elapsed       | 504       |\n","|    total_timesteps    | 89000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17799     |\n","|    policy_loss        | 2.06e+08  |\n","|    reward             | 1829103.2 |\n","|    std                | 0.936     |\n","|    value_loss         | 3.44e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1871320.400957997\n","Sharpe:  0.8755023395929282\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 17900     |\n","|    time_elapsed       | 507       |\n","|    total_timesteps    | 89500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 17899     |\n","|    policy_loss        | 1.6e+08   |\n","|    reward             | 1342770.4 |\n","|    std                | 0.935     |\n","|    value_loss         | 1.9e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1714754.6483551164\n","Sharpe:  0.7672246213841551\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 176        |\n","|    iterations         | 18000      |\n","|    time_elapsed       | 510        |\n","|    total_timesteps    | 90000      |\n","| train/                |            |\n","|    entropy_loss       | -39.2      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0002     |\n","|    n_updates          | 17999      |\n","|    policy_loss        | 1.15e+08   |\n","|    reward             | 1006008.44 |\n","|    std                | 0.936      |\n","|    value_loss         | 1.1e+13    |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18100     |\n","|    time_elapsed       | 513       |\n","|    total_timesteps    | 90500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18099     |\n","|    policy_loss        | 1.65e+08  |\n","|    reward             | 1397401.6 |\n","|    std                | 0.936     |\n","|    value_loss         | 2.1e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1836658.6604592232\n","Sharpe:  0.8503943499731177\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18200     |\n","|    time_elapsed       | 516       |\n","|    total_timesteps    | 91000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18199     |\n","|    policy_loss        | 1.28e+08  |\n","|    reward             | 1087699.9 |\n","|    std                | 0.936     |\n","|    value_loss         | 1.23e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18300     |\n","|    time_elapsed       | 519       |\n","|    total_timesteps    | 91500     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18299     |\n","|    policy_loss        | 1.71e+08  |\n","|    reward             | 1463573.1 |\n","|    std                | 0.935     |\n","|    value_loss         | 2.36e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1807547.9303102475\n","Sharpe:  0.8290338413573469\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18400     |\n","|    time_elapsed       | 522       |\n","|    total_timesteps    | 92000     |\n","| train/                |           |\n","|    entropy_loss       | -39.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18399     |\n","|    policy_loss        | 1.33e+08  |\n","|    reward             | 1132915.2 |\n","|    std                | 0.934     |\n","|    value_loss         | 1.34e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18500     |\n","|    time_elapsed       | 525       |\n","|    total_timesteps    | 92500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18499     |\n","|    policy_loss        | 1.76e+08  |\n","|    reward             | 1489077.5 |\n","|    std                | 0.934     |\n","|    value_loss         | 2.26e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1893426.8084218344\n","Sharpe:  0.8915607867331172\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18600     |\n","|    time_elapsed       | 528       |\n","|    total_timesteps    | 93000     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 1.79e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18599     |\n","|    policy_loss        | 1.33e+08  |\n","|    reward             | 1206065.8 |\n","|    std                | 0.933     |\n","|    value_loss         | 1.51e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18700     |\n","|    time_elapsed       | 530       |\n","|    total_timesteps    | 93500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18699     |\n","|    policy_loss        | 1.77e+08  |\n","|    reward             | 1550044.9 |\n","|    std                | 0.933     |\n","|    value_loss         | 2.5e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1744054.1466161646\n","Sharpe:  0.7853445482969041\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18800     |\n","|    time_elapsed       | 533       |\n","|    total_timesteps    | 94000     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18799     |\n","|    policy_loss        | 1.4e+08   |\n","|    reward             | 1167946.9 |\n","|    std                | 0.933     |\n","|    value_loss         | 1.64e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 18900     |\n","|    time_elapsed       | 536       |\n","|    total_timesteps    | 94500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18899     |\n","|    policy_loss        | 1.48e+08  |\n","|    reward             | 1177714.2 |\n","|    std                | 0.933     |\n","|    value_loss         | 1.9e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1867749.6110456595\n","Sharpe:  0.8723581793033309\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19000     |\n","|    time_elapsed       | 539       |\n","|    total_timesteps    | 95000     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 18999     |\n","|    policy_loss        | 1.49e+08  |\n","|    reward             | 1249500.0 |\n","|    std                | 0.933     |\n","|    value_loss         | 1.57e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19100     |\n","|    time_elapsed       | 542       |\n","|    total_timesteps    | 95500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19099     |\n","|    policy_loss        | 1.61e+08  |\n","|    reward             | 1474521.4 |\n","|    std                | 0.932     |\n","|    value_loss         | 2.09e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1787521.522353489\n","Sharpe:  0.817917904855447\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19200     |\n","|    time_elapsed       | 545       |\n","|    total_timesteps    | 96000     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19199     |\n","|    policy_loss        | 1.48e+08  |\n","|    reward             | 1319941.2 |\n","|    std                | 0.931     |\n","|    value_loss         | 1.8e+13   |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19300     |\n","|    time_elapsed       | 547       |\n","|    total_timesteps    | 96500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19299     |\n","|    policy_loss        | 1.88e+08  |\n","|    reward             | 1577798.1 |\n","|    std                | 0.931     |\n","|    value_loss         | 2.67e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1816049.8687246523\n","Sharpe:  0.8399513170225198\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19400     |\n","|    time_elapsed       | 550       |\n","|    total_timesteps    | 97000     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19399     |\n","|    policy_loss        | 1.47e+08  |\n","|    reward             | 1353648.9 |\n","|    std                | 0.931     |\n","|    value_loss         | 1.77e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19500     |\n","|    time_elapsed       | 553       |\n","|    total_timesteps    | 97500     |\n","| train/                |           |\n","|    entropy_loss       | -39.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19499     |\n","|    policy_loss        | 1.89e+08  |\n","|    reward             | 1632429.0 |\n","|    std                | 0.931     |\n","|    value_loss         | 2.93e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1865758.5588391034\n","Sharpe:  0.8758949822701342\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19600     |\n","|    time_elapsed       | 556       |\n","|    total_timesteps    | 98000     |\n","| train/                |           |\n","|    entropy_loss       | -39       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19599     |\n","|    policy_loss        | 1.63e+08  |\n","|    reward             | 1306139.0 |\n","|    std                | 0.931     |\n","|    value_loss         | 1.82e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1834592.151171096\n","Sharpe:  0.8493062318143415\n","=================================\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 175      |\n","|    iterations         | 19700    |\n","|    time_elapsed       | 559      |\n","|    total_timesteps    | 98500    |\n","| train/                |          |\n","|    entropy_loss       | -39      |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0002   |\n","|    n_updates          | 19699    |\n","|    policy_loss        | 1.18e+08 |\n","|    reward             | 993216.6 |\n","|    std                | 0.931    |\n","|    value_loss         | 1.06e+13 |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 176       |\n","|    iterations         | 19800     |\n","|    time_elapsed       | 562       |\n","|    total_timesteps    | 99000     |\n","| train/                |           |\n","|    entropy_loss       | -39       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19799     |\n","|    policy_loss        | 1.53e+08  |\n","|    reward             | 1414647.2 |\n","|    std                | 0.93      |\n","|    value_loss         | 2.1e+13   |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1879091.2015989241\n","Sharpe:  0.8799607668621311\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 175       |\n","|    iterations         | 19900     |\n","|    time_elapsed       | 565       |\n","|    total_timesteps    | 99500     |\n","| train/                |           |\n","|    entropy_loss       | -39       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19899     |\n","|    policy_loss        | 1.25e+08  |\n","|    reward             | 1046233.5 |\n","|    std                | 0.929     |\n","|    value_loss         | 1.16e+13  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 175       |\n","|    iterations         | 20000     |\n","|    time_elapsed       | 568       |\n","|    total_timesteps    | 100000    |\n","| train/                |           |\n","|    entropy_loss       | -39       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0002    |\n","|    n_updates          | 19999     |\n","|    policy_loss        | 1.75e+08  |\n","|    reward             | 1437413.6 |\n","|    std                | 0.929     |\n","|    value_loss         | 2.19e+13  |\n","-------------------------------------\n","=================================\n","begin_total_asset:1000000\n","end_total_asset:1196141.4744178853\n","Sharpe:  1.86539317625355\n","=================================\n","hit end!\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/PawPol/PyPortOpt.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrh9S5PAems_","executionInfo":{"status":"ok","timestamp":1639446047766,"user_tz":300,"elapsed":4843,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"outputId":"bd057da7-0266-4813-fcfd-45d1fac1b0ff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","Collecting git+https://github.com/PawPol/PyPortOpt.git\n","  Cloning https://github.com/PawPol/PyPortOpt.git to /tmp/pip-req-build-10ctqxzk\n","  Running command git clone -q https://github.com/PawPol/PyPortOpt.git /tmp/pip-req-build-10ctqxzk\n","Requirement already satisfied: numpy==1.21.0 in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (1.21.0)\n","Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (1.3.0)\n","Requirement already satisfied: osqp in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (0.6.2.post0)\n","Requirement already satisfied: scipy==1.7.0 in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (1.7.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (3.2.2)\n","Requirement already satisfied: quantstats in /usr/local/lib/python3.7/dist-packages (from PyPortOpt==0.1) (0.0.47)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0->PyPortOpt==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0->PyPortOpt==0.1) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0->PyPortOpt==0.1) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyPortOpt==0.1) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyPortOpt==0.1) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyPortOpt==0.1) (0.11.0)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp->PyPortOpt==0.1) (0.1.5.post0)\n","Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from quantstats->PyPortOpt==0.1) (0.11.2)\n","Requirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from quantstats->PyPortOpt==0.1) (0.8.9)\n","Requirement already satisfied: yfinance>=0.1.63 in /usr/local/lib/python3.7/dist-packages (from quantstats->PyPortOpt==0.1) (0.1.67)\n","Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (4.7.1)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (2.23.0)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (0.0.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance>=0.1.63->quantstats->PyPortOpt==0.1) (1.24.3)\n","\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"]}]},{"cell_type":"code","source":["df = YahooDownloader(start_date = '2017-01-01',\n","                     end_date = '2021-11-03',\n","                     ticker_list = config.DOW_30_TICKER).fetch_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDsvl_QCe1JC","executionInfo":{"status":"ok","timestamp":1639446059046,"user_tz":300,"elapsed":8212,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"outputId":"1621f2b7-d7dd-4363-a691-4a537675fd32"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (35982, 8)\n"]}]},{"cell_type":"code","source":["from PyPortOpt import Optimizers as o\n","# import pandas as pd\n","# import quantstats as qs"],"metadata":{"id":"_E9Jmyube7NF","executionInfo":{"status":"ok","timestamp":1639446067998,"user_tz":300,"elapsed":134,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["R, df_logret, w_all, rownames = o.rollingwindow_backtest(\n","            \"minimumVariancePortfolio\", df[['date', 'tic', 'close']], 60, 1\n","        )"],"metadata":{"id":"Pxv9zwo5e7sQ","executionInfo":{"status":"ok","timestamp":1639446748713,"user_tz":300,"elapsed":25671,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["return_s = pd.Series(R[-211:] / 100)\n","return_s.index = pd.DatetimeIndex(rownames[-211:])"],"metadata":{"id":"xlosC8Fxe_8P","executionInfo":{"status":"ok","timestamp":1639446749933,"user_tz":300,"elapsed":129,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["return_drl = pd.Series(test_return[\"daily_return\"])\n","return_drl.index = pd.DatetimeIndex(test_return[\"date\"])"],"metadata":{"id":"wRsVP6TifStV","executionInfo":{"status":"ok","timestamp":1639447574796,"user_tz":300,"elapsed":140,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["return_drl.shape, return_s.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abhhmEFWf68U","executionInfo":{"status":"ok","timestamp":1639446751775,"user_tz":300,"elapsed":155,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}},"outputId":"e4476cf0-8171-424a-8392-9dfb1678eb7c"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((211,), (211,))"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["return_s.to_csv(\"return_minVar.csv\")"],"metadata":{"id":"E-PiCtJXmlT9","executionInfo":{"status":"ok","timestamp":1639446753298,"user_tz":300,"elapsed":137,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["return_drl.to_csv(\"return_drl.csv\")"],"metadata":{"id":"6PXi4FmwiC5k","executionInfo":{"status":"ok","timestamp":1639447583430,"user_tz":300,"elapsed":132,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["import quantstats as qs"],"metadata":{"id":"Zrh-DAvXmsin","executionInfo":{"status":"ok","timestamp":1639446143157,"user_tz":300,"elapsed":516,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["qs.reports.html(return_drl, return_s, output=\"DRL_vs_MVP_3.html\")"],"metadata":{"id":"RvitX1G4fERP","executionInfo":{"status":"ok","timestamp":1639447591976,"user_tz":300,"elapsed":5632,"user":{"displayName":"Maxence Guegnolle--Santi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13323283606504048467"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0adeK14GfYzK"},"execution_count":null,"outputs":[]}]}